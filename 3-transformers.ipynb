{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using HuggingFace Transformers for Sentiment Analysis\n## Pre-Trained vs Fine-Tuned Models","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:07:21.943524Z","iopub.execute_input":"2023-02-09T13:07:21.944005Z","iopub.status.idle":"2023-02-09T13:07:21.949401Z","shell.execute_reply.started":"2023-02-09T13:07:21.943970Z","shell.execute_reply":"2023-02-09T13:07:21.948248Z"}}},{"cell_type":"markdown","source":"### 1. Dataset\n\n#### Load and clean up the dataset","metadata":{}},{"cell_type":"code","source":"%%time\nimport numpy as np\nimport pandas as pd\n\ndata = pd.read_csv('/kaggle/input/phonereviews/data.csv')\ndata = data.dropna()\ndata_filtered = data.loc[data['Rating'].isin({1, 2, 4, 5})]\ndf = data_filtered\ndf = df.reset_index(drop=True)\ndf.loc[(df['Rating'] >= 4), 'Sentiment'] = 'positive'\ndf.loc[(df['Rating'] <= 2), 'Sentiment'] = 'negative'\ndf = df.loc[df['Review'].apply(lambda text: len(text) >= 20)]\ndf['Sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:26:20.562003Z","iopub.execute_input":"2023-02-11T10:26:20.562671Z","iopub.status.idle":"2023-02-11T10:26:28.989916Z","shell.execute_reply.started":"2023-02-11T10:26:20.562631Z","shell.execute_reply":"2023-02-11T10:26:28.988911Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"CPU times: user 4.63 s, sys: 510 ms, total: 5.14 s\nWall time: 8.41 s\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"positive    326183\nnegative     67920\nName: Sentiment, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Split into train and test sets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntexts = df['Review'].values\nlabels = df['Sentiment'].values\nX_train, X_test, y_train, y_test = train_test_split(\n    texts,\n    labels,\n    test_size=0.1,\n    random_state=1,\n)\nprint(f'len(X_train) = {len(X_train)}')\nprint(f'len(y_train) = {len(y_train)}')\nprint(f'len(X_test) = {len(X_test)}')\nprint(f'len(y_test) = {len(y_test)}')","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:33:49.424929Z","iopub.execute_input":"2023-02-11T10:33:49.425550Z","iopub.status.idle":"2023-02-11T10:33:49.494122Z","shell.execute_reply.started":"2023-02-11T10:33:49.425513Z","shell.execute_reply":"2023-02-11T10:33:49.492987Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"len(X_train) = 354692\nlen(y_train) = 354692\nlen(X_test) = 39411\nlen(y_test) = 39411\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 2. Use a pre-trained HuggingFace Transformer model\n\nThe model: https://huggingface.co/cointegrated/rubert-tiny-sentiment-balanced  \nIt has 12M parameters.","metadata":{}},{"cell_type":"markdown","source":"#### First, prepare the tokenizer and the model","metadata":{}},{"cell_type":"code","source":"!pip install transformers sentencepiece --quiet","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:50:15.013021Z","iopub.execute_input":"2023-02-11T10:50:15.013437Z","iopub.status.idle":"2023-02-11T10:50:25.934021Z","shell.execute_reply.started":"2023-02-11T10:50:15.013402Z","shell.execute_reply":"2023-02-11T10:50:25.932795Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel_checkpoint = 'cointegrated/rubert-tiny-sentiment-balanced'\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel_pretrained = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\nif torch.cuda.is_available():\n    model_pretrained.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:53:19.306693Z","iopub.execute_input":"2023-02-11T10:53:19.307743Z","iopub.status.idle":"2023-02-11T10:53:28.267784Z","shell.execute_reply.started":"2023-02-11T10:53:19.307699Z","shell.execute_reply":"2023-02-11T10:53:28.266675Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/377 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed0e76f52e3d4528ae54b6368fb31ea1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/235k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c65b5a3cf84e45619c96c15ffa95e937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/457k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6d5d29977340beac4b183aba55dfe4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99a79112ef454736ab72e70732fcd99d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/884 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7bd8df4b72b4107a211bfa8b48c8dae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/45.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c04081f0fac432fba7f0a91209f5374"}},"metadata":{}}]},{"cell_type":"markdown","source":"#### Define a model-independent function that will return a prediction for a single text","metadata":{}},{"cell_type":"code","source":"from typing_extensions import Literal  \n# from typing import Literal  # in Python 3.8+\n\ndef predict(\n    model: AutoModelForSequenceClassification, \n    text: str, \n    return_type: Literal['label', 'score', 'proba'] = 'label',\n):\n    with torch.no_grad():\n        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(model.device)\n        proba = torch.sigmoid(model(**inputs).logits).cpu().numpy()[0]\n    if return_type == 'label':\n        return model.config.id2label[proba.argmax()]\n    elif return_type == 'score':\n        return proba.dot([-1, 0, 1])\n    return proba","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:57:57.487850Z","iopub.execute_input":"2023-02-11T10:57:57.488351Z","iopub.status.idle":"2023-02-11T10:57:57.498821Z","shell.execute_reply.started":"2023-02-11T10:57:57.488310Z","shell.execute_reply":"2023-02-11T10:57:57.497775Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### Run a couple of simple tests","metadata":{}},{"cell_type":"code","source":"text = 'Какая гадость эта ваша заливная рыба!'\n# classify the text\nprint(predict(model_pretrained, text, 'label'))  # negative\n# score the text on the scale from -1 (very negative) to +1 (very positive)\nprint(predict(model_pretrained, text, 'score'))  # -0.5894946306943893\n# calculate probabilities of all labels\nprint(predict(model_pretrained, text, 'proba'))  # [0.7870447  0.4947824  0.19755007]","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:58:01.462419Z","iopub.execute_input":"2023-02-11T10:58:01.463333Z","iopub.status.idle":"2023-02-11T10:58:02.512888Z","shell.execute_reply.started":"2023-02-11T10:58:01.463297Z","shell.execute_reply":"2023-02-11T10:58:02.511866Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"negative\n-0.5894946306943893\n[0.7870447  0.4947824  0.19755007]\n","output_type":"stream"}]},{"cell_type":"code","source":"examples = [\n    'Отличный телефон - сколько пользуюсь, столько и радуюсь',\n    'Ужасный телефон, хуже некуда!',\n    'Сегодня отличная погода!',\n    'У Васи ужасное настроение.',\n    'Эта модель основана на трансформерах.'\n]\nfor example in examples:\n    print(predict(model_pretrained, example))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:01:10.267378Z","iopub.execute_input":"2023-02-11T11:01:10.268073Z","iopub.status.idle":"2023-02-11T11:01:10.294132Z","shell.execute_reply.started":"2023-02-11T11:01:10.268035Z","shell.execute_reply":"2023-02-11T11:01:10.293151Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"positive\nnegative\npositive\nnegative\nneutral\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Define a model-independent function for evaluation on the test set","metadata":{}},{"cell_type":"code","source":"from typing import Optional\n\nfrom sklearn.metrics import classification_report\nfrom tqdm.auto import tqdm\n\ndef evaluate_model(\n    model: AutoModelForSequenceClassification, \n    subset: Optional[int] = None,\n):\n    y_pred = []\n    \n    if subset is None:\n        subset = X_test.shape[0]\n    \n    for x in tqdm(X_test[:subset]):\n        prediction = predict(model, x)\n        y_pred.append(prediction)\n        \n    print(classification_report(y_test[:subset], y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:03:13.937601Z","iopub.execute_input":"2023-02-11T11:03:13.937976Z","iopub.status.idle":"2023-02-11T11:03:13.944858Z","shell.execute_reply.started":"2023-02-11T11:03:13.937947Z","shell.execute_reply":"2023-02-11T11:03:13.943517Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluate the pre-trained model on the test set","metadata":{}},{"cell_type":"code","source":"%%time\n\nevaluate_model(model_pretrained)  # takes about 15-18 min on CPU, 2 min on T100 GPU","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-02-11T11:03:54.744525Z","iopub.execute_input":"2023-02-11T11:03:54.745567Z","iopub.status.idle":"2023-02-11T11:05:56.726342Z","shell.execute_reply.started":"2023-02-11T11:03:54.745509Z","shell.execute_reply":"2023-02-11T11:05:56.725314Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/39411 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a051335de9d540acbee8b1d34a38d6cf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    negative       0.40      0.55      0.46      6742\n     neutral       0.00      0.00      0.00         0\n    positive       0.96      0.45      0.62     32669\n\n    accuracy                           0.47     39411\n   macro avg       0.45      0.34      0.36     39411\nweighted avg       0.86      0.47      0.59     39411\n\nCPU times: user 2min 1s, sys: 471 ms, total: 2min 1s\nWall time: 2min 1s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"(0.46 + 0.62) / 2","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:06:47.478785Z","iopub.execute_input":"2023-02-11T11:06:47.479158Z","iopub.status.idle":"2023-02-11T11:06:47.486938Z","shell.execute_reply.started":"2023-02-11T11:06:47.479129Z","shell.execute_reply":"2023-02-11T11:06:47.485847Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.54"},"metadata":{}}]},{"cell_type":"markdown","source":"The results are not so good, because the model was trained on other domains than mobile phones.","metadata":{}},{"cell_type":"markdown","source":"### 3. Fine-tune the pre-trained model on our dataset","metadata":{}},{"cell_type":"markdown","source":"#### Split the training data into train and dev","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\n\nn_train_examples = 10000\nn_dev_examples = 5000\ntrain_df = pd.DataFrame(\n    {\n        'text': X_train[:n_train_examples],\n        'label': y_train[:n_train_examples],\n    }\n)\ndev_df = pd.DataFrame(\n    {\n        'text': X_train[n_train_examples:n_train_examples + n_dev_examples],\n        'label': y_train[n_train_examples:n_train_examples + n_dev_examples],\n    }\n)\n\ndata = DatasetDict(\n    {\n        'train': Dataset.from_pandas(train_df[['text', 'label']].reset_index(drop=True)),\n        'dev': Dataset.from_pandas(dev_df[['text', 'label']].reset_index(drop=True)),\n    }\n)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:10:06.035798Z","iopub.execute_input":"2023-02-11T11:10:06.036262Z","iopub.status.idle":"2023-02-11T11:10:06.133563Z","shell.execute_reply.started":"2023-02-11T11:10:06.036226Z","shell.execute_reply":"2023-02-11T11:10:06.132481Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 10000\n    })\n    dev: Dataset({\n        features: ['text', 'label'],\n        num_rows: 5000\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Tokenize the data","metadata":{}},{"cell_type":"code","source":"all_labels = ['negative', 'neutral', 'positive']\ndata_tokenized = data.map(\n    lambda row: tokenizer(row['text'], truncation=True), batched=True, remove_columns=['text']\n)\ndata_tokenized = data_tokenized.map(\n    lambda row: {'label': [all_labels.index(label) for label in row['label']]}, batched=True\n)\ndata_tokenized","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:11:33.990600Z","iopub.execute_input":"2023-02-11T11:11:33.991019Z","iopub.status.idle":"2023-02-11T11:11:41.330059Z","shell.execute_reply.started":"2023-02-11T11:11:33.990984Z","shell.execute_reply":"2023-02-11T11:11:41.329150Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a91a0f97b2c42d786261542c28074a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f4892e2b29148baa095be86ffb283f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d7b539112744909b462ddd139838d06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a23d324a32474b9dab33059bffae7d57"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 10000\n    })\n    dev: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 5000\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Prepare for training","metadata":{}},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:11:53.423662Z","iopub.execute_input":"2023-02-11T11:11:53.424372Z","iopub.status.idle":"2023-02-11T11:12:03.868045Z","shell.execute_reply.started":"2023-02-11T11:11:53.424325Z","shell.execute_reply":"2023-02-11T11:12:03.866797Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m892.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (6.0.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (23.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2023.1.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.10.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (5.0.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2022.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:12:20.226808Z","iopub.execute_input":"2023-02-11T11:12:20.227248Z","iopub.status.idle":"2023-02-11T11:12:20.232833Z","shell.execute_reply.started":"2023-02-11T11:12:20.227214Z","shell.execute_reply":"2023-02-11T11:12:20.231612Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import evaluate\nfrom transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n\ndata_collator = DataCollatorWithPadding(tokenizer)\n\ntraining_args = TrainingArguments(\n    output_dir='test_trainer', \n    evaluation_strategy='epoch',\n)\nmetric = evaluate.load('accuracy')\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(\n        predictions=predictions, \n        references=labels,\n    )\n\ntrainer = Trainer(\n    model=model_pretrained,\n    args=training_args,\n    train_dataset=data_tokenized['train'],\n    eval_dataset=data_tokenized['dev'],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:13:42.325194Z","iopub.execute_input":"2023-02-11T11:13:42.325631Z","iopub.status.idle":"2023-02-11T11:13:46.367085Z","shell.execute_reply.started":"2023-02-11T11:13:42.325598Z","shell.execute_reply":"2023-02-11T11:13:46.366126Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37949742f4c2433eb9f80bd3b1211f06"}},"metadata":{}}]},{"cell_type":"markdown","source":"#### Train and save model","metadata":{}},{"cell_type":"code","source":"trainer.train()  # GPU recommended","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:13:55.015165Z","iopub.execute_input":"2023-02-11T11:13:55.015870Z","iopub.status.idle":"2023-02-11T11:16:40.034795Z","shell.execute_reply.started":"2023-02-11T11:13:55.015831Z","shell.execute_reply":"2023-02-11T11:16:40.033687Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 10000\n  Num Epochs = 3\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 3750\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3750/3750 02:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.316700</td>\n      <td>0.312359</td>\n      <td>0.880200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.258700</td>\n      <td>0.413976</td>\n      <td>0.880000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.174200</td>\n      <td>0.491137</td>\n      <td>0.882800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to test_trainer/checkpoint-500\nConfiguration saved in test_trainer/checkpoint-500/config.json\nModel weights saved in test_trainer/checkpoint-500/pytorch_model.bin\nSaving model checkpoint to test_trainer/checkpoint-1000\nConfiguration saved in test_trainer/checkpoint-1000/config.json\nModel weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 5000\n  Batch size = 8\nSaving model checkpoint to test_trainer/checkpoint-1500\nConfiguration saved in test_trainer/checkpoint-1500/config.json\nModel weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\nSaving model checkpoint to test_trainer/checkpoint-2000\nConfiguration saved in test_trainer/checkpoint-2000/config.json\nModel weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\nSaving model checkpoint to test_trainer/checkpoint-2500\nConfiguration saved in test_trainer/checkpoint-2500/config.json\nModel weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 5000\n  Batch size = 8\nSaving model checkpoint to test_trainer/checkpoint-3000\nConfiguration saved in test_trainer/checkpoint-3000/config.json\nModel weights saved in test_trainer/checkpoint-3000/pytorch_model.bin\nSaving model checkpoint to test_trainer/checkpoint-3500\nConfiguration saved in test_trainer/checkpoint-3500/config.json\nModel weights saved in test_trainer/checkpoint-3500/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 5000\n  Batch size = 8\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3750, training_loss=0.25770050557454427, metrics={'train_runtime': 164.9778, 'train_samples_per_second': 181.843, 'train_steps_per_second': 22.73, 'total_flos': 152357844439008.0, 'train_loss': 0.25770050557454427, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('my_finetuned_model')","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:16:54.709699Z","iopub.execute_input":"2023-02-11T11:16:54.710087Z","iopub.status.idle":"2023-02-11T11:16:54.882401Z","shell.execute_reply.started":"2023-02-11T11:16:54.710053Z","shell.execute_reply":"2023-02-11T11:16:54.881280Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Saving model checkpoint to my_finetuned_model\nConfiguration saved in my_finetuned_model/config.json\nModel weights saved in my_finetuned_model/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Load the fine-tuned model","metadata":{}},{"cell_type":"code","source":"# checkpoint = 'test_trainer/checkpoint-3000'  # 500, 1000, 1500, 2000, 3000\ncheckpoint = 'my_finetuned_model'\ntokenizer = AutoTokenizer.from_pretrained('cointegrated/rubert-tiny-sentiment-balanced')\nmodel_finetuned = AutoModelForSequenceClassification.from_pretrained(checkpoint)\nif torch.cuda.is_available():\n    model_finetuned.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:17:34.825740Z","iopub.execute_input":"2023-02-11T11:17:34.826228Z","iopub.status.idle":"2023-02-11T11:17:37.417071Z","shell.execute_reply.started":"2023-02-11T11:17:34.826180Z","shell.execute_reply":"2023-02-11T11:17:37.416152Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"loading file https://huggingface.co/cointegrated/rubert-tiny-sentiment-balanced/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/92c2b9e2fa0ff2385ddcfaa42bc3c80da2b518d8c1d06f818f81606932015085.77a9cd5f52c58bd231a1d3bc7390917dc6d0fadc0f17cee179994e8dfe382aba\nloading file https://huggingface.co/cointegrated/rubert-tiny-sentiment-balanced/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/beec8a371470ceff29166c53d40c56610e7e250be63a650526981481d04346e2.4fda28baf56969bde43ae6200f8299c1370bfd2992311ef8f737e7d619d8b5ed\nloading file https://huggingface.co/cointegrated/rubert-tiny-sentiment-balanced/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/cointegrated/rubert-tiny-sentiment-balanced/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4e57ac0d61c767e7d5db0f3b9e68f622ddedacc5730d4d01d5079eb011ff67ef.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\nloading file https://huggingface.co/cointegrated/rubert-tiny-sentiment-balanced/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/905a6a95326b845d2e162992b8d38e2b2b9b2f22732a340f26bdf7633bc4d587.0686bf48e2ccfbf6a033757e905edd63bfc0f5390254d8049ed29538fa3d812a\nloading configuration file my_finetuned_model/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"my_finetuned_model\",\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"emb_size\": 312,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 312,\n  \"id2label\": {\n    \"0\": \"negative\",\n    \"1\": \"neutral\",\n    \"2\": \"positive\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 600,\n  \"label2id\": {\n    \"negative\": 0,\n    \"neutral\": 1,\n    \"positive\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 3,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"single_label_classification\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 29564\n}\n\nloading weights file my_finetuned_model/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the model checkpoint at my_finetuned_model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"examples = [\n    'Отличный телефон - сколько пользуюсь, столько и радуюсь',\n    'Ужасный телефон, хуже некуда!',\n    'Сегодня отличная погода!',\n    'У Васи ужасное настроение.',\n    'Эта модель основана на трансформерах.'\n]\nfor example in examples:\n    print(predict(model_finetuned, example))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:18:05.315025Z","iopub.execute_input":"2023-02-11T11:18:05.315421Z","iopub.status.idle":"2023-02-11T11:18:05.339920Z","shell.execute_reply.started":"2023-02-11T11:18:05.315388Z","shell.execute_reply":"2023-02-11T11:18:05.338816Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"positive\nnegative\npositive\nnegative\npositive\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Evaluation","metadata":{}},{"cell_type":"code","source":"print(checkpoint)\nevaluate_model(model_finetuned)  # GPU recommended","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:18:57.808910Z","iopub.execute_input":"2023-02-11T11:18:57.809323Z","iopub.status.idle":"2023-02-11T11:21:06.144634Z","shell.execute_reply.started":"2023-02-11T11:18:57.809289Z","shell.execute_reply":"2023-02-11T11:21:06.143653Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"my_finetuned_model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/39411 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ea71eea64664ead9f8e6bc4698e9f97"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    negative       0.69      0.62      0.65      6742\n     neutral       0.00      0.00      0.00         0\n    positive       0.92      0.94      0.93     32669\n\n    accuracy                           0.89     39411\n   macro avg       0.54      0.52      0.53     39411\nweighted avg       0.88      0.89      0.89     39411\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"(0.65 + 0.93) / 2","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:21:26.284987Z","iopub.execute_input":"2023-02-11T11:21:26.285373Z","iopub.status.idle":"2023-02-11T11:21:26.292713Z","shell.execute_reply.started":"2023-02-11T11:21:26.285339Z","shell.execute_reply":"2023-02-11T11:21:26.291635Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0.79"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Things to try further\n* balanced dataset\n* larger training data\n* hyperparameter tuning\n* sentence transformers!","metadata":{}}]}